{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3ee99a7-0a63-4058-bdee-369d6c2f0122",
   "metadata": {},
   "source": [
    "# Data processing for bump hunt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2411f5a9-06b8-42c2-9f2c-0d6c3acd17af",
   "metadata": {},
   "source": [
    "Main differences for bump hunt:\n",
    "- No fully supervised set\n",
    "- test set covers the whole SR / SB range\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26433067-97c1-4a2c-9b62-5cb6b7cf674c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from helpers.plotting import *\n",
    "from helpers.physics_functions import *\n",
    "from helpers.data_transforms import *\n",
    "\n",
    "plt.style.use(\"../science.mplstyle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb1506e-478c-4ca6-88be-bea7cdc06935",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(\"workflow.yaml\", \"r\") as file:\n",
    "    workflow = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e679a068-79e8-4bd2-adc2-1010dac2f6ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_nojet opp sign (21803678,)\n",
      "DATA_nojet same sign (6756613,)\n"
     ]
    }
   ],
   "source": [
    "project_id = \"lowmass\"\n",
    "scaler_id = \"logit_08_22\"\n",
    "\n",
    "working_dir = \"/global/cfs/cdirs/m3246/rmastand/dimuonAD\"\n",
    "path_to_compiled_data = f\"{working_dir}/compiled_data/{project_id}\"\n",
    "    \n",
    "    \n",
    "run_jet = False\n",
    "if run_jet:\n",
    "    codes_list = [\"DATA_jet\"]\n",
    "    sim_id = \"DATA_jet\" # should probably rename this to data_id\n",
    "else:\n",
    "    codes_list = [\"DATA_nojet\"]\n",
    "    sim_id = \"DATA_nojet\" # should probably rename this to data_id\n",
    "signal_id = \"\"\n",
    "\n",
    "    \n",
    "uncut_data, uncut_data_samesign = {code:{} for code in codes_list},  {code:{} for code in codes_list}\n",
    "\n",
    "for code in codes_list:\n",
    "    with open(f\"{path_to_compiled_data}/{code}\", \"rb\") as ifile:\n",
    "        tmp_dict = pickle.load(ifile)\n",
    "        for key in tmp_dict.keys():\n",
    "            if \"samesign\" in key:\n",
    "                uncut_data_samesign[code][key[:-9]] = tmp_dict[key]\n",
    "            else:\n",
    "                uncut_data[code][key] = tmp_dict[key]\n",
    "        \n",
    "    \n",
    "    print(code, \"opp sign\",  uncut_data[code][list(uncut_data[code].keys())[0]].shape)\n",
    "    print(code, \"same sign\", uncut_data_samesign[code][list(uncut_data[code].keys())[0]].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c982c8-50b6-4235-880e-5904bf934f33",
   "metadata": {},
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "357e179e-049f-4449-82c0-4539af8f714b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mu0_ip3d', 'mu1_ip3d', 'mu0_jetiso', 'mu1_jetiso', 'mu0_eta', 'mu1_eta', 'mu0_pt', 'mu1_pt', 'mu0_phi', 'mu1_phi', 'mu0_iso04', 'mu1_iso04', 'dimu_pt', 'dimu_eta', 'dimu_phi', 'n_muons', 'n_jets', 'dimu_mass', 'mumu_deltaR', 'mumu_deltapT']\n"
     ]
    }
   ],
   "source": [
    "feature_set = list(uncut_data[codes_list[0]].keys())\n",
    "print(feature_set)\n",
    "\n",
    "#hist_all_features_dict([uncut_data[codes_list[0]]], codes_list, feature_set, kwargs_dict_dtype, nice_labels=True)\n",
    "print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7601bfc0-a52a-418a-9e46-93d646d7024c",
   "metadata": {},
   "source": [
    "## Make cuts\n",
    "\n",
    "Now let's define cuts on the data. \n",
    "\n",
    "Muon cuts were made previously (and we don't want to make cuts on the dimuon system, either)\n",
    "\n",
    "Random seed is used to set aside a portion of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d395893c-375c-4ff9-8fba-8a84974cc7c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "particle_type = \"upsilon\"\n",
    "analysis_test = \"iso\" # iso, pt, none\n",
    "\n",
    "\n",
    "if particle_type == \"upsilon\":    \n",
    "    iso_cut = 0.55\n",
    "    pt_cut = None\n",
    "    if analysis_test == \"iso\":\n",
    "        N_test = 25000\n",
    "        random_seed = 4 # 2.5 for cubic\n",
    "\n",
    "\n",
    "elif particle_type == \"psi_prime\":    \n",
    "    pt_cut = None\n",
    "    if analysis_test == \"iso_low\":\n",
    "        iso_cut = 0.7\n",
    "        N_test = 1000\n",
    "        random_seed = 9 # 2.85\n",
    "    elif analysis_test == \"iso_high\":\n",
    "        iso_cut = 1.1\n",
    "        N_test = 10000\n",
    "        random_seed = 11 # 2.76    \n",
    "        \n",
    "if particle_type == \"psi\":\n",
    "    iso_cut = 8\n",
    "    pt_cut = None\n",
    "    if analysis_test == \"iso\":\n",
    "        N_test = 1000\n",
    "        random_seed = 13 # 2.76\n",
    "        \n",
    "        \n",
    "if particle_type == \"rho\":\n",
    "    iso_cut = None\n",
    "    pt_cut = 60\n",
    "    if analysis_test == \"pt\":\n",
    "        N_test = 3000\n",
    "        random_seed = 12 # 2.78\n",
    "    \n",
    "elif particle_type == \"eta\":\n",
    "    mass = 0.547\n",
    "    iso_cut = 0\n",
    "    pt_cut = None\n",
    "    if analysis_test == \"none\":\n",
    "        N_test = 40000\n",
    "        random_seed = 4 # 2.82\n",
    "    if analysis_test == \"none_2\" or analysis_test == \"none_3\":\n",
    "        N_test = 150000\n",
    "        random_seed = 4 # 2.82\n",
    "    if analysis_test == \"iso\":\n",
    "        N_test = 50000\n",
    "        random_seed = 5 # 3.4\n",
    "\n",
    "SB_left = float(workflow[particle_type][\"SB_left\"])\n",
    "SR_left = float(workflow[particle_type][\"SR_left\"])\n",
    "SR_right = float(workflow[particle_type][\"SR_right\"])\n",
    "SB_right = float(workflow[particle_type][\"SB_right\"])\n",
    "\n",
    "\n",
    "band_bounds = {\"SBL\": [SB_left,SR_left],\n",
    "                   \"SR\": [SR_left,SR_right],\n",
    "                   \"SBH\": [SR_right,SB_right],\n",
    "                           }\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "plot_bins_SR = np.linspace(SR_left, SR_right, 6)\n",
    "width = plot_bins_SR[1] - plot_bins_SR[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6434c2f7-f1c1-46af-a084-452432fb9436",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_data, cut_data_samesign = {code:{} for code in codes_list},  {code:{} for code in codes_list}\n",
    "\n",
    "for code in codes_list:\n",
    "    \n",
    "    # define cuts to reduce the starting significance\n",
    "    if \"iso\" in analysis_test:\n",
    "        print()\n",
    "        pass_indices = (uncut_data[code][\"mu0_iso04\"] >= iso_cut) & (uncut_data[code][\"mu1_iso04\"] >= iso_cut)\n",
    "        pass_indices_samesign = (uncut_data_samesign[code][\"mu0_iso04\"] >= iso_cut) & (uncut_data_samesign[code][\"mu1_iso04\"] >= iso_cut)\n",
    "        \n",
    "    elif analysis_test == \"pt\":\n",
    "        pass_indices = (uncut_data[code][\"dimu_pt\"] >= pt_cut)\n",
    "        pass_indices_samesign = (uncut_data_samesign[code][\"dimu_pt\"] >= pt_cut)\n",
    "        \n",
    "    elif analysis_test == \"none\" or analysis_test == \"none_2\" or analysis_test == \"none_3\":\n",
    "        pass_indices = (uncut_data[code][\"dimu_pt\"] >= -1)\n",
    "        pass_indices_samesign = (uncut_data_samesign[code][\"dimu_pt\"] >= -1)\n",
    "        \n",
    "        \n",
    "    \n",
    "    # apply cuts to oppsign\n",
    "    for feat in feature_set:\n",
    "        cut_data[code][feat] = uncut_data[code][feat][pass_indices]\n",
    "    # apply cuts to samesign\n",
    "    for feat in feature_set:\n",
    "        cut_data_samesign[code][feat] = uncut_data_samesign[code][feat][pass_indices_samesign]\n",
    "    \n",
    "    print(f\"{code} oppsign has shape {cut_data[code][feat].shape} after cuts\")\n",
    "    print(f\"{code} samesign has shape {cut_data_samesign[code][feat].shape} after cuts\")\n",
    "    \n",
    "    \n",
    "#hist_all_features_dict([cut_data[\"DATA_nojet\"]], [\"DATA_nojet\"], feature_set, kwargs_dict_dtype, nice_labels=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209a95ef-1362-4f8a-8250-54c1c7ebec62",
   "metadata": {},
   "source": [
    "Check how local cuts affect the starting significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82364f41-679c-4a03-9711-8fd23b47c246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "bkg_fit_type = \"cubic\"\n",
    "bkg_fit_function = bkg_fit_cubic\n",
    "plot_bins_all, plot_bins_SR, plot_bins_left, plot_bins_right, plot_centers_all, plot_centers_SR, plot_centers_SB = get_bins(SR_left, SR_right, SB_left, SB_right, num_bins_SR= 16)\n",
    "\n",
    "SR_center = 0.5*(plot_bins_SR[0]+plot_bins_SR[-1])\n",
    "print(0.01*SR_center)\n",
    "print(plot_bins_SR[1]-plot_bins_SR[0])\n",
    "\n",
    "x = np.linspace(SB_left, SB_right, 100) # plot curve fit\n",
    "\n",
    "masses_with_bounds = cut_data[code][\"dimu_mass\"][(cut_data[code][\"dimu_mass\"] >= SB_left) & (cut_data[code][\"dimu_mass\"] <= SB_right)]\n",
    "masses_with_bounds_samesign = cut_data_samesign[code][\"dimu_mass\"][(cut_data_samesign[code][\"dimu_mass\"] >= SB_left) & (cut_data_samesign[code][\"dimu_mass\"] <= SB_right)]\n",
    "\n",
    "print(masses_with_bounds.shape)\n",
    "plt.figure(figsize = (7,5))\n",
    "\n",
    "# plot all data\n",
    "loc_data = masses_with_bounds\n",
    "print(loc_data.shape)\n",
    "popt_0, _, _, _, _ = curve_fit_m_inv(loc_data, bkg_fit_type, SR_left, SR_right, plot_bins_left, plot_bins_right, plot_centers_all)\n",
    "\n",
    "plt.plot(x, bkg_fit_function(x, *popt_0), lw = 3, linestyle = \"dashed\")\n",
    "num_S_expected_in_SR, num_B_expected_in_SR = calc_significance(loc_data, bkg_fit_function, plot_bins_SR, SR_left, SR_right, popt_0)\n",
    "\n",
    "plt.hist(loc_data, bins = plot_bins_all, lw = 2, histtype = \"step\", density = False, label = f\"S/B: {round(num_S_expected_in_SR/num_B_expected_in_SR,3)}, S/sqrt(B): {round(num_S_expected_in_SR/np.sqrt(num_B_expected_in_SR),3)}\")\n",
    "\n",
    "\n",
    "# plot subset of data\n",
    "np.random.shuffle(masses_with_bounds)\n",
    "loc_data = masses_with_bounds[:N_test]\n",
    "popt_0, _, _, _, _ = curve_fit_m_inv(loc_data, bkg_fit_type, SR_left, SR_right, plot_bins_left, plot_bins_right, plot_centers_all)\n",
    "plt.plot(x, bkg_fit_function(x, *popt_0), lw = 3, linestyle = \"dashed\")\n",
    "num_S_expected_in_SR, num_B_expected_in_SR = calc_significance(loc_data, bkg_fit_function, plot_bins_SR, SR_left, SR_right, popt_0)\n",
    "plt.hist(loc_data, bins = plot_bins_all, lw = 2, histtype = \"step\", density = False, label = f\"S/B: {round(num_S_expected_in_SR/num_B_expected_in_SR,3)}, S/sqrt(B): {round(num_S_expected_in_SR/np.sqrt(num_B_expected_in_SR),3)}\")\n",
    "\n",
    "\n",
    "plt.axvline(SR_left)\n",
    "plt.axvline(SR_right)\n",
    "\n",
    "plt.xlabel(\"Dimu M [GeV]\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.legend(loc = (1, 0))\n",
    "\n",
    "#plt.yscale(\"log\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    " \n",
    "    \n",
    "#hist_all_features(codes_list, cut_data, feature_set, kwargs_dict_dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0b85da-fd08-43b5-90ae-15b0950486e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize = (7,5))\n",
    "\n",
    "# plot all data\n",
    "loc_data = masses_with_bounds\n",
    "plt.hist(loc_data, bins = plot_bins_all, lw = 2, histtype = \"step\", density = True, label = f\"opp sign\")\n",
    "plt.hist(masses_with_bounds_samesign, bins = plot_bins_all, lw = 2, histtype = \"step\", density = True, label = f\"same sign\")\n",
    "\n",
    "\n",
    "plt.xlabel(\"Dimu M [GeV]\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend(loc = (1, 0))\n",
    "\n",
    "\n",
    "plt.show()\n",
    " \n",
    "    \n",
    "#hist_all_features(codes_list, cut_data, feature_set, kwargs_dict_dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089c12ec-2ba4-4dcc-933f-249167e278e1",
   "metadata": {},
   "source": [
    "Split data into bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076c8893-c905-4d2d-b712-c0e2105b3350",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bands = [\"SBL\", \"SR\", \"SBH\"]\n",
    "N_total_events = 0\n",
    "N_total_events_samesign = 0\n",
    "\n",
    "\n",
    "\n",
    "preproc_dicts, preproc_dicts_samesign = {b:{} for b in bands}, {b:{} for b in bands}\n",
    "\n",
    "\n",
    "for code in codes_list:\n",
    "    for b in bands:\n",
    "\n",
    "        # opp sign\n",
    "        loc_pass_indices = (cut_data[code][\"dimu_mass\"] >= band_bounds[b][0]) & (cut_data[code][\"dimu_mass\"] < band_bounds[b][1])\n",
    "        preproc_dicts[b][code] = {}\n",
    "        for feat in feature_set:\n",
    "            preproc_dicts[b][code][feat] = cut_data[code][feat][loc_pass_indices]\n",
    "            \n",
    "       \n",
    "        N_total_events += preproc_dicts[b][code][feat].shape[0]\n",
    "        \n",
    "        # same sign\n",
    "        loc_pass_indices_samesign = (cut_data_samesign[code][\"dimu_mass\"] >= band_bounds[b][0]) & (cut_data_samesign[code][\"dimu_mass\"] < band_bounds[b][1])\n",
    "        preproc_dicts_samesign[b][code] = {}\n",
    "        for feat in feature_set:\n",
    "            preproc_dicts_samesign[b][code][feat] = cut_data_samesign[code][feat][loc_pass_indices_samesign]\n",
    "            \n",
    "        N_total_events_samesign += preproc_dicts_samesign[b][code][feat].shape[0]\n",
    "  \n",
    "    \n",
    "    \n",
    "print(f\"Total events opp sign: {N_total_events}\")\n",
    "print(f\"Total events same sign: {N_total_events_samesign}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590d0e9d-6eff-4b17-9488-4c3e1cc9905a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e4b33b8-25c4-4af5-8ec3-b3c150249789",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Standard scaling is fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806bdc34-9be1-45b8-82ac-c79c11bd4138",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sizes_dict, sizes_dict_samesign = {}, {}\n",
    "\n",
    "\n",
    "proccessed_data_dict, proccessed_data_dict_samesign  = {b:{\"s_inj_data\":{}} for b in bands}, {b:{\"s_inj_data\":{}} for b in bands}\n",
    "\n",
    "for feat in feature_set: \n",
    "    \n",
    "    # train the preprocessor on the opp sign data only\n",
    "    data_SB = np.hstack((preproc_dicts[\"SBL\"][sim_id][feat], preproc_dicts[\"SBH\"][sim_id][feat])).reshape(-1, 1)\n",
    "    \n",
    "    if feat == \"dimu_mass\": # don't logit transform\n",
    "        mass_scaler = StandardScaler()\n",
    "        mass_scaler = mass_scaler.fit(data_SB)\n",
    "        \n",
    "        with open(f\"{working_dir}/projects/{scaler_id}/processed_data/mass_scaler_{particle_type}_{analysis_test}\", \"wb\") as ofile:\n",
    "            pickle.dump(mass_scaler, ofile)\n",
    "            \n",
    "        for b in bands:\n",
    "            proccessed_data_dict[b][\"s_inj_data\"][feat] = mass_scaler.transform(preproc_dicts[b][sim_id][feat].reshape(-1,1))\n",
    "            proccessed_data_dict_samesign[b][\"s_inj_data\"][feat] =  mass_scaler.transform(preproc_dicts_samesign[b][sim_id][feat].reshape(-1,1))\n",
    "            sizes_dict[b] = proccessed_data_dict[b][\"s_inj_data\"][feat].shape[0]\n",
    "            sizes_dict_samesign[b] = proccessed_data_dict_samesign[b][\"s_inj_data\"][feat].shape[0]\n",
    "    \n",
    "        \n",
    "    else: \n",
    "        \n",
    "        data_all = np.hstack((preproc_dicts[\"SBL\"][sim_id][feat], preproc_dicts[\"SBH\"][sim_id][feat], preproc_dicts[\"SR\"][sim_id][feat])).reshape(-1, 1)\n",
    "        all_min = np.min(data_all)\n",
    "        all_max = np.max(data_all)\n",
    "        # logit transform the features\n",
    "    \n",
    "        transformed_feats = logit_transform(data_SB, all_min, all_max)\n",
    "        # subtract off mean, std of the training set\n",
    "        mean_to_sub = np.mean(transformed_feats)\n",
    "        std_to_sub = np.std(transformed_feats)\n",
    "\n",
    "    \n",
    "        for b in bands:\n",
    "            proccessed_data_dict[b][\"s_inj_data\"][feat] = (logit_transform(preproc_dicts[b][sim_id][feat], all_min, all_max) - mean_to_sub)/std_to_sub\n",
    "            proccessed_data_dict_samesign[b][\"s_inj_data\"][feat] = (logit_transform(preproc_dicts_samesign[b][sim_id][feat], all_min, all_max) - mean_to_sub)/std_to_sub\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d5105e-bb86-4e82-a30d-fed0fd4d5088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(sizes_dict)\n",
    "print(sizes_dict_samesign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7080a019-aa16-40b9-801b-5a87663ffe34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist_all_features_dict([proccessed_data_dict[\"SBL\"][\"s_inj_data\"], proccessed_data_dict[\"SBH\"][\"s_inj_data\"], proccessed_data_dict[\"SR\"][\"s_inj_data\"]], \n",
    "                       [\"SBL\", \"SBH\", \"SR\"], feature_set, kwargs_dict_bands, scaled_features=True, plot_bound=5, image_path=None, yscale_log=False, nice_labels=True)\n",
    "\n",
    "\n",
    "hist_all_features_dict([proccessed_data_dict_samesign[\"SBL\"][\"s_inj_data\"], proccessed_data_dict_samesign[\"SBH\"][\"s_inj_data\"], proccessed_data_dict_samesign[\"SR\"][\"s_inj_data\"]], \n",
    "                       [\"SBL\", \"SBH\", \"SR\"], feature_set, kwargs_dict_bands, scaled_features=True, plot_bound=10, image_path=None, yscale_log=False, nice_labels=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4333a0-ffcd-4d47-890e-9596edde5486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specify a percentage of events to set aside for the test set\n",
    "\n",
    "\n",
    "train_data_dict = {b:{\"s_inj_data\":{}} for b in bands}\n",
    "test_data_dict = {b:{\"s_inj_data\":{}} for b in bands}\n",
    "\n",
    "train_data_dict_samesign = {b:{\"s_inj_data\":{}} for b in bands}\n",
    "test_data_dict_samesign = {b:{\"s_inj_data\":{}} for b in bands}\n",
    "\n",
    "\n",
    "print(sizes_dict)\n",
    "\n",
    "for b in bands:\n",
    "    \n",
    "    random_seed = 4\n",
    "    \n",
    "    # make sets for opp sign\n",
    "    \n",
    "    # get indices to select\n",
    "    loc_num_test_events = int((N_test/N_total_events)*sizes_dict[b])\n",
    "    \n",
    "    np.random.seed(random_seed)\n",
    "    test_set_inds = np.random.choice(range(sizes_dict[b]), size = loc_num_test_events, replace = False)\n",
    "    train_set_inds = np.setdiff1d(list(range(sizes_dict[b])),test_set_inds)\n",
    "        \n",
    "    for feat in feature_set:\n",
    " \n",
    "        train_data_dict[b][\"s_inj_data\"][feat] = proccessed_data_dict[b][\"s_inj_data\"][feat][train_set_inds]\n",
    "        test_data_dict[b][\"s_inj_data\"][feat] = proccessed_data_dict[b][\"s_inj_data\"][feat][test_set_inds]\n",
    "        \n",
    "    # make sets for same sign\n",
    "    if particle_type == \"eta\":\n",
    "        loc_num_test_events_samesign = np.int((2000/N_total_events_samesign)*sizes_dict_samesign[b])\n",
    "    elif particle_type == \"rho\":\n",
    "        loc_num_test_events_samesign = np.int((10/N_total_events_samesign)*sizes_dict_samesign[b])\n",
    "    else:\n",
    "        loc_num_test_events_samesign = np.int((N_test/N_total_events_samesign)*sizes_dict_samesign[b])\n",
    "    \n",
    "    np.random.seed(random_seed)\n",
    "    test_set_inds_samesign = np.random.choice(range(sizes_dict_samesign[b]), size = loc_num_test_events_samesign, replace = False)\n",
    "    train_set_inds_samesign = np.setdiff1d(list(range(sizes_dict_samesign[b])),test_set_inds_samesign)\n",
    "        \n",
    "    for feat in feature_set:\n",
    " \n",
    "        train_data_dict_samesign[b][\"s_inj_data\"][feat] = proccessed_data_dict_samesign[b][\"s_inj_data\"][feat][train_set_inds_samesign]\n",
    "        test_data_dict_samesign[b][\"s_inj_data\"][feat] = proccessed_data_dict_samesign[b][\"s_inj_data\"][feat][test_set_inds_samesign]\n",
    "\n",
    "\n",
    "test_set_size = test_data_dict[\"SR\"][\"s_inj_data\"][\"dimu_mass\"].shape[0] + test_data_dict[\"SBL\"][\"s_inj_data\"][\"dimu_mass\"].shape[0]+ test_data_dict[\"SBH\"][\"s_inj_data\"][\"dimu_mass\"].shape[0]\n",
    "train_set_size = train_data_dict[\"SR\"][\"s_inj_data\"][\"dimu_mass\"].shape[0] + train_data_dict[\"SBL\"][\"s_inj_data\"][\"dimu_mass\"].shape[0]+ train_data_dict[\"SBH\"][\"s_inj_data\"][\"dimu_mass\"].shape[0]\n",
    "\n",
    "test_set_size_samesign = test_data_dict_samesign[\"SR\"][\"s_inj_data\"][\"dimu_mass\"].shape[0] + test_data_dict_samesign[\"SBL\"][\"s_inj_data\"][\"dimu_mass\"].shape[0]+ test_data_dict_samesign[\"SBH\"][\"s_inj_data\"][\"dimu_mass\"].shape[0]\n",
    "train_set_size_samesign = train_data_dict_samesign[\"SR\"][\"s_inj_data\"][\"dimu_mass\"].shape[0] + train_data_dict_samesign[\"SBL\"][\"s_inj_data\"][\"dimu_mass\"].shape[0]+ train_data_dict_samesign[\"SBH\"][\"s_inj_data\"][\"dimu_mass\"].shape[0]\n",
    "\n",
    "print(f\"{test_set_size} test events (target: {N_test}). {train_set_size} train events\")    \n",
    "print(f\"{test_set_size_samesign} samesign test events (target: {N_test}). {train_set_size_samesign} samesign train events\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dff8207-506b-4d1e-a707-d394ef6f7e37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## trial_train_set = mass_scaler.inverse_transform(np.concatenate((train_data_dict[\"SBL\"][\"s_inj_data\"][\"dimu_mass\"], train_data_dict[\"SBH\"][\"s_inj_data\"][\"dimu_mass\"], train_data_dict[\"SR\"][\"s_inj_data\"][\"dimu_mass\"])))\n",
    "trial_test_set = mass_scaler.inverse_transform(np.concatenate((test_data_dict[\"SBL\"][\"s_inj_data\"][\"dimu_mass\"], test_data_dict[\"SBH\"][\"s_inj_data\"][\"dimu_mass\"], test_data_dict[\"SR\"][\"s_inj_data\"][\"dimu_mass\"])))\n",
    "#trial_test_set = mass_scaler.inverse_transform(np.concatenate((test_data_dict_samesign[\"SBL\"][\"s_inj_data\"][\"dimu_mass\"], test_data_dict_samesign[\"SBH\"][\"s_inj_data\"][\"dimu_mass\"], test_data_dict_samesign[\"SR\"][\"s_inj_data\"][\"dimu_mass\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc77114-e67d-4756-952e-59a0dffe79ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "x = np.linspace(SB_left, SB_right, 100)\n",
    "\n",
    "# get bins, bin centers\n",
    "plot_bins_all, plot_bins_SR, plot_bins_left, plot_bins_right, plot_centers_all, plot_centers_SR, plot_centers_SB = get_bins(SR_left, SR_right, SB_left, SB_right)\n",
    "\n",
    "\n",
    "fit_type = \"cubic\"\n",
    "if fit_type == \"cubic\": fit_function = bkg_fit_cubic\n",
    "elif fit_type == \"quintic\":nfit_function = bkg_fit_quintic\n",
    "elif fit_type == \"ratio\": fit_function = bkg_fit_ratio\n",
    "\n",
    "plt.figure(figsize = (12, 9))\n",
    "\n",
    "\n",
    "# get the fit function to SB background\n",
    "popt, pcov, chi2, y_vals, n_dof = curve_fit_m_inv(trial_test_set, fit_type, SR_left, SR_right, plot_bins_left, plot_bins_right, plot_centers_all, SBL_rescale=None, SBH_rescale=None)\n",
    "#print(\"chi2/dof:\", chi2/n_dof)\n",
    "# plot the fit function\n",
    "plt.plot(plot_centers_all, fit_function(plot_centers_all, *popt), lw = 2, linestyle = \"dashed\")    \n",
    "\n",
    "# calculate significance of bump\n",
    "num_S_expected_in_SR, num_B_expected_in_SR = calc_significance(trial_test_set, fit_function, plot_bins_SR, SR_left, SR_right, popt)\n",
    "\n",
    "\n",
    "y_err = get_errors_bkg_fit_ratio(popt, pcov, plot_centers_SR, fit_type)\n",
    "B_error = np.sqrt(np.sum(y_err**2))\n",
    "print(num_S_expected_in_SR, num_B_expected_in_SR)\n",
    "\n",
    "print(\"S/B\", num_S_expected_in_SR/num_B_expected_in_SR)\n",
    "print(\"sigma_b^2/ b\", B_error**2/num_B_expected_in_SR)\n",
    "        \n",
    "S_over_B = num_S_expected_in_SR/num_B_expected_in_SR\n",
    "significance = num_S_expected_in_SR/np.sqrt(num_B_expected_in_SR+B_error**2)\n",
    "\n",
    "label_string = \"$S/B$: \"+str(round(S_over_B,4))+\", $S/\\sqrt{B}$: \"+str(round(significance,4))\n",
    "\n",
    "plt.hist(trial_test_set, bins = plot_bins_all, lw = 3, histtype = \"step\",label = label_string)\n",
    "plt.scatter(plot_centers_SB, y_vals)\n",
    "    \n",
    "    \n",
    "\n",
    "print() \n",
    "plt.legend(loc = (1, 0), fontsize = 24)\n",
    "\n",
    "\n",
    "plt.axvline(SR_left, color= \"k\", lw = 3, zorder = -10)\n",
    "plt.axvline(SR_right, color= \"k\", lw = 3, zorder = -10)\n",
    "\n",
    "plt.xlabel(\"$M_{\\mu\\mu}$ [GeV]\", fontsize = 24)\n",
    "plt.ylabel(\"Counts\", fontsize = 24)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05e28c9-c8d1-449b-a453-b8d46f1f3376",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "if run_jet:\n",
    "    with open(f\"{working_dir}/projects/{scaler_id}/processed_data/{project_id}_{particle_type}_{analysis_test}_jet_train_band_data\", \"wb\") as ofile:\n",
    "        pickle.dump(train_data_dict, ofile)\n",
    "\n",
    "\n",
    "    with open(f\"{working_dir}/projects/{scaler_id}/processed_data/{project_id}_{particle_type}_{analysis_test}_jet_test_band_data\", \"wb\") as ofile:\n",
    "        pickle.dump(test_data_dict, ofile)\n",
    "\n",
    "\n",
    "\n",
    "    with open(f\"{working_dir}/projects/{scaler_id}/processed_data/{project_id}_{particle_type}_{analysis_test}_samesign_jet_train_band_data\", \"wb\") as ofile:\n",
    "        pickle.dump(train_data_dict_samesign, ofile)\n",
    "\n",
    "\n",
    "    with open(f\"{working_dir}/projects/{scaler_id}/processed_data/{project_id}_{particle_type}_{analysis_test}_samesign_jet_test_band_data\", \"wb\") as ofile:\n",
    "        pickle.dump(test_data_dict_samesign, ofile)\n",
    "\n",
    "else:\n",
    "    with open(f\"{working_dir}/projects/{scaler_id}/processed_data/{project_id}_{particle_type}_{analysis_test}_nojet_train_band_data\", \"wb\") as ofile:\n",
    "        pickle.dump(train_data_dict, ofile)\n",
    "\n",
    "\n",
    "    with open(f\"{working_dir}/projects/{scaler_id}/processed_data/{project_id}_{particle_type}_{analysis_test}_nojet_test_band_data\", \"wb\") as ofile:\n",
    "        pickle.dump(test_data_dict, ofile)\n",
    "\n",
    "\n",
    "\n",
    "    with open(f\"{working_dir}/projects/{scaler_id}/processed_data/{project_id}_{particle_type}_{analysis_test}_samesign_nojet_train_band_data\", \"wb\") as ofile:\n",
    "        pickle.dump(train_data_dict_samesign, ofile)\n",
    "\n",
    "\n",
    "    with open(f\"{working_dir}/projects/{scaler_id}/processed_data/{project_id}_{particle_type}_{analysis_test}_samesign_nojet_test_band_data\", \"wb\") as ofile:\n",
    "        pickle.dump(test_data_dict_samesign, ofile)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6542b296-826b-446e-ad19-31c557d76630",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06cbe07-44f5-4a5d-99df-d67d27b0d3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7800495d-0f11-4907-9b50-518c6f8f754d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5551d7-64a4-424d-a238-47d4989c7db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b1899b-7586-485e-8f3f-953c0116ac19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ce6e7a-b502-4e2f-9df5-e181c9247e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df17ba0a-1f8f-45e9-986e-497ff7cf6bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
