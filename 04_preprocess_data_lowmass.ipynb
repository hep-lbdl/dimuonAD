{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3ee99a7-0a63-4058-bdee-369d6c2f0122",
   "metadata": {},
   "source": [
    "# Data processing for single window bump hunt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26433067-97c1-4a2c-9b62-5cb6b7cf674c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from helpers.plotting import *\n",
    "from helpers.physics_functions import *\n",
    "from helpers.data_transforms import bootstrap_array, logit_transform\n",
    "\n",
    "plt.style.use(\"../science.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb1506e-478c-4ca6-88be-bea7cdc06935",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(\"workflow.yaml\", \"r\") as file:\n",
    "    workflow = yaml.safe_load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbfeb86-80a9-4e30-a006-782029139482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processed_data_dir = workflow[\"file_paths\"][\"data_storage_dir\"] +\"/projects/\"+workflow[\"analysis_keywords\"][\"name\"]+\"/processed_data/\"\n",
    "os.makedirs(processed_data_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e679a068-79e8-4bd2-adc2-1010dac2f6ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'skimmed_data_2016H_30555_nojet': array([10689005,  7960136, 11972118, ...,  2079696,  1885067, 15099980])} {'skimmed_data_2016H_30555_nojet': array([1924264, 6392335, 2300397, ..., 1875377, 2884890, 2560683])}\n",
      "skimmed_data_2016H_30555_nojet opp sign (21803678,)\n",
      "skimmed_data_2016H_30555_nojet same sign (6756613,)\n"
     ]
    }
   ],
   "source": [
    "bootstrap_seed = 2 # if 0, don't bootstrap\n",
    "\n",
    "working_dir = workflow[\"file_paths\"][\"working_dir\"]\n",
    "path_to_compiled_data = workflow[\"file_paths\"][\"data_storage_dir\"]+\"/compiled_data/\"+workflow[\"analysis_keywords\"][\"dataset_id\"]\n",
    "    \n",
    "codes_list = [\"skimmed_data_2016H_30555_nojet\"] # may want multiple codes for injection studies\n",
    "\n",
    "\n",
    "# bootstrap the data (if applicable)\n",
    "bootstrap_indices_OS, bootstrap_indices_SS = {}, {}\n",
    "for code in codes_list:\n",
    "    with open(f\"{path_to_compiled_data}/{code}\", \"rb\") as ifile:\n",
    "        tmp_dict = pickle.load(ifile)\n",
    "        num_events_OS = len(tmp_dict[\"dimu_mass\"])\n",
    "        num_events_SS = len(tmp_dict[\"dimu_mass_samesign\"])\n",
    "        if bootstrap_seed > 0:\n",
    "            np.random.seed(bootstrap_seed)\n",
    "            indices_to_take_OS = np.random.choice(num_events_OS, size = num_events_OS, replace = True) \n",
    "            np.random.seed(bootstrap_seed)\n",
    "            indices_to_take_SS = np.random.choice(num_events_SS, size = num_events_SS, replace = True) \n",
    "        else:\n",
    "            indices_to_take_OS = range(num_events_OS)\n",
    "            indices_to_take_SS = range(num_events_SS)\n",
    "        bootstrap_indices_OS[code] = indices_to_take_OS\n",
    "        bootstrap_indices_SS[code] = indices_to_take_SS\n",
    "\n",
    "print(bootstrap_indices_OS, bootstrap_indices_SS)\n",
    "\n",
    "\n",
    "uncut_data_OS, uncut_data_SS = {code:{} for code in codes_list},  {code:{} for code in codes_list}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for code in codes_list:\n",
    "    with open(f\"{path_to_compiled_data}/{code}\", \"rb\") as ifile:\n",
    "        tmp_dict = pickle.load(ifile)\n",
    "        for key in tmp_dict.keys():\n",
    "            if \"samesign\" in key:\n",
    "                uncut_data_SS[code][key[:-9]] = tmp_dict[key][bootstrap_indices_SS[code]]\n",
    "            else:\n",
    "                uncut_data_OS[code][key] = tmp_dict[key][bootstrap_indices_OS[code]]\n",
    "\n",
    "    print(code, \"opp sign\",  uncut_data_OS[code][list(uncut_data_OS[code].keys())[0]].shape)\n",
    "    print(code, \"same sign\", uncut_data_SS[code][list(uncut_data_SS[code].keys())[0]].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68464b6b-16ad-4f81-973c-a725cb2b3e30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dimu_pt', 'dimu_eta', 'dimu_phi', 'n_muons', 'n_jets', 'dimu_mass', 'mu0_ip3d', 'mu1_ip3d', 'mu0_jetiso', 'mu1_jetiso', 'mu0_eta', 'mu1_eta', 'mu0_pt', 'mu1_pt', 'mu0_phi', 'mu1_phi', 'mu0_iso04', 'mu1_iso04', 'mumu_deltaR', 'mumu_deltapT']\n"
     ]
    }
   ],
   "source": [
    "feature_set = list(uncut_data_OS[codes_list[0]].keys())\n",
    "feature_set = [x for x in feature_set if \"HLT\" not in x]\n",
    "print(feature_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7601bfc0-a52a-418a-9e46-93d646d7024c",
   "metadata": {},
   "source": [
    "## Make cuts\n",
    "\n",
    "Now let's define cuts on the data. \n",
    "\n",
    "Muon cuts were made previously (and we don't want to make cuts on the dimuon system, either)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6434c2f7-f1c1-46af-a084-452432fb9436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SBL': [5.0, 9.0], 'SR': [9.0, 10.6], 'SBH': [10.6, 16.0]}\n",
      "skimmed_data_2016H_30555_nojet OS has shape (12254,) after cuts\n",
      "skimmed_data_2016H_30555_nojet SS has shape (7161,) after cuts\n"
     ]
    }
   ],
   "source": [
    "SB_left = float(workflow[\"window_definitions\"][workflow[\"analysis_keywords\"][\"particle\"]][\"SB_left\"])\n",
    "SR_left = float(workflow[\"window_definitions\"][workflow[\"analysis_keywords\"][\"particle\"]][\"SR_left\"])\n",
    "SR_right = float(workflow[\"window_definitions\"][workflow[\"analysis_keywords\"][\"particle\"]][\"SR_right\"])\n",
    "SB_right = float(workflow[\"window_definitions\"][workflow[\"analysis_keywords\"][\"particle\"]][\"SB_right\"])\n",
    "\n",
    "\n",
    "band_bounds = {\"SBL\": [SB_left,SR_left],\n",
    "                   \"SR\": [SR_left,SR_right],\n",
    "                   \"SBH\": [SR_right,SB_right],\n",
    "                           }\n",
    "\n",
    "print(band_bounds)\n",
    "\n",
    "cut_data_OS, cut_data_SS = {code:{} for code in codes_list},  {code:{} for code in codes_list}\n",
    "\n",
    "\n",
    "analysis_cuts_dict = workflow[\"analysis_keywords\"][\"analysis_cuts\"]\n",
    "\n",
    "for code in codes_list:\n",
    "\n",
    "    pass_indices_OS = np.ones((uncut_data_OS[code][\"dimu_mass\"].shape[0]))\n",
    "    pass_indices_SS = np.ones((uncut_data_SS[code][\"dimu_mass\"].shape[0]))\n",
    "    try:\n",
    "        a = analysis_cuts_dict[\"lower\"].keys()\n",
    "        for cut_var in analysis_cuts_dict[\"lower\"].keys():\n",
    "            pass_indices_OS = np.logical_and(pass_indices_OS, uncut_data_OS[code][cut_var] >= analysis_cuts_dict[\"lower\"][cut_var])\n",
    "            pass_indices_SS = np.logical_and(pass_indices_SS, uncut_data_SS[code][cut_var] >= analysis_cuts_dict[\"lower\"][cut_var])\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        a = analysis_cuts_dict[\"upper\"].keys()\n",
    "        for cut_var in analysis_cuts_dict[\"upper\"].keys():\n",
    "            pass_indices_OS = np.logical_and(pass_indices_OS, uncut_data_OS[code][cut_var] <= analysis_cuts_dict[\"upper\"][cut_var])\n",
    "            pass_indices_SS = np.logical_and(pass_indices_SS, uncut_data_SS[code][cut_var] <= analysis_cuts_dict[\"upper\"][cut_var])\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    pass_indices_OS = np.logical_and(pass_indices_OS, (uncut_data_OS[code][\"dimu_mass\"] >= SB_left) & (uncut_data_OS[code][\"dimu_mass\"] <= SB_right))\n",
    "    pass_indices_SS = np.logical_and(pass_indices_SS, (uncut_data_SS[code][\"dimu_mass\"] >= SB_left) & (uncut_data_SS[code][\"dimu_mass\"] <= SB_right))\n",
    "\n",
    "\n",
    "    # apply cuts to oppsign\n",
    "    for feat in feature_set:\n",
    "        cut_data_OS[code][feat] = uncut_data_OS[code][feat][pass_indices_OS]\n",
    "        cut_data_SS[code][feat] = uncut_data_SS[code][feat][pass_indices_SS]\n",
    "    \n",
    "    print(f\"{code} OS has shape {cut_data_OS[code][feat].shape} after cuts\")\n",
    "    print(f\"{code} SS has shape {cut_data_SS[code][feat].shape} after cuts\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e35fb1-a72f-46ad-8989-9ddee0d7ec8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kwargs_dict_dtype = {\"OS\":{\"density\": True, \"histtype\": \"step\", \"color\":\"blue\", \"label\": \"OS\"},\n",
    "                    \"SS\":{\"density\": True, \"histtype\": \"step\", \"color\":\"red\", \"label\": \"SS\"}}\n",
    "        \n",
    "hist_all_features_dict([cut_data_OS[codes_list[0]], cut_data_SS[codes_list[0]]], [\"OS\", \"SS\"], feature_set, kwargs_dict_dtype, nice_labels=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209a95ef-1362-4f8a-8250-54c1c7ebec62",
   "metadata": {},
   "source": [
    "Check how local cuts affect the starting significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82364f41-679c-4a03-9711-8fd23b47c246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bkg_fit_type = \"quintic\"\n",
    "num_bins_SR = 12\n",
    "bkg_fit_function = bkg_fit_quintic\n",
    "plot_bins_all, plot_bins_SR, plot_bins_left, plot_bins_right, plot_centers_all, plot_centers_SR, plot_centers_SB = get_bins(SR_left, SR_right, SB_left, SB_right, num_bins_SR= num_bins_SR)\n",
    "\n",
    "x = np.linspace(SB_left, SB_right, 100) # plot curve fit\n",
    "\n",
    "plt.figure(figsize = (7,5))\n",
    "\n",
    "# plot all data\n",
    "popt_0, pcov_0, _, _, _ = curve_fit_m_inv(cut_data_OS[code][\"dimu_mass\"], bkg_fit_type, SR_left, SR_right, plot_bins_left, plot_bins_right, plot_centers_SB)\n",
    "\n",
    "plt.plot(x, bkg_fit_function(x, *popt_0), lw = 3, linestyle = \"dashed\")\n",
    "S, B, q0 = calculate_test_statistic(cut_data_OS[code][\"dimu_mass\"], bkg_fit_function, bkg_fit_type, plot_bins_SR, plot_centers_SR, SR_left, SR_right, popt_0, pcov_0)\n",
    "\n",
    "plt.hist(cut_data_OS[code][\"dimu_mass\"], bins = plot_bins_all, lw = 2, histtype = \"step\", density = False, label = f\"sig: {round(np.sqrt(q0),3)}\")\n",
    "\n",
    "plt.axvline(SR_left)\n",
    "plt.axvline(SR_right)\n",
    "\n",
    "plt.xlabel(\"Dimu M [GeV]\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.legend(loc = (1, 0))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0b85da-fd08-43b5-90ae-15b0950486e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize = (7,5))\n",
    "\n",
    "# plot all data\n",
    "plt.hist(cut_data_OS[code][\"dimu_mass\"], bins = plot_bins_all, lw = 2, histtype = \"step\", density = True, label = f\"opp sign\")\n",
    "plt.hist(cut_data_SS[code][\"dimu_mass\"], bins = plot_bins_all, lw = 2, histtype = \"step\", density = True, label = f\"same sign\")\n",
    "plt.xlabel(\"Dimu M [GeV]\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend(loc = (1, 0))\n",
    "plt.show()\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089c12ec-2ba4-4dcc-933f-249167e278e1",
   "metadata": {},
   "source": [
    "Split data into bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076c8893-c905-4d2d-b712-c0e2105b3350",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bands = [\"SBL\", \"SR\", \"SBH\"]\n",
    "N_total_events_OS = 0\n",
    "N_total_events_SS = 0\n",
    "\n",
    "\n",
    "preproc_dicts_OS, preproc_dicts_SS = {b:{} for b in bands}, {b:{} for b in bands}\n",
    "\n",
    "\n",
    "for code in codes_list:\n",
    "    for b in bands:\n",
    "\n",
    "        # opp sign\n",
    "        loc_pass_indices_OS = (cut_data_OS[code][\"dimu_mass\"] >= band_bounds[b][0]) & (cut_data_OS[code][\"dimu_mass\"] < band_bounds[b][1])\n",
    "        preproc_dicts_OS[b][code] = {}\n",
    "        for feat in feature_set:\n",
    "            preproc_dicts_OS[b][code][feat] = cut_data_OS[code][feat][loc_pass_indices_OS]\n",
    "            \n",
    "       \n",
    "        N_total_events_OS += preproc_dicts_OS[b][code][feat].shape[0]\n",
    "        \n",
    "        # same sign\n",
    "        loc_pass_indices_SS = (cut_data_SS[code][\"dimu_mass\"] >= band_bounds[b][0]) & (cut_data_SS[code][\"dimu_mass\"] < band_bounds[b][1])\n",
    "        preproc_dicts_SS[b][code] = {}\n",
    "        for feat in feature_set:\n",
    "            preproc_dicts_SS[b][code][feat] = cut_data_SS[code][feat][loc_pass_indices_SS]\n",
    "            \n",
    "        N_total_events_SS += preproc_dicts_SS[b][code][feat].shape[0]\n",
    "  \n",
    "    \n",
    "    \n",
    "print(f\"Total events opp sign: {N_total_events_OS}\")\n",
    "print(f\"Total events same sign: {N_total_events_SS}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4b33b8-25c4-4af5-8ec3-b3c150249789",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Standard scaling is fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806bdc34-9be1-45b8-82ac-c79c11bd4138",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sizes_dict_OS, sizes_dict_SS = {}, {}\n",
    "\n",
    "preprocessing_info = {}\n",
    "proccessed_data_dict_OS, proccessed_data_dict_SS  = {b:{} for b in bands}, {b:{} for b in bands}\n",
    "\n",
    "for feat in feature_set: \n",
    "    \n",
    "    # train the preprocessor on the opp sign data only\n",
    "    data_SB = np.hstack((preproc_dicts_OS[\"SBL\"][code][feat], preproc_dicts_OS[\"SBH\"][code][feat])).reshape(-1, 1)\n",
    "    \n",
    "    if feat == \"dimu_mass\": # don't logit transform\n",
    "        mass_scaler = StandardScaler()\n",
    "        mass_scaler = mass_scaler.fit(data_SB)\n",
    "      \n",
    "        with open(f\"{processed_data_dir}/mass_scaler_bootstrap{bootstrap_seed}\", \"wb\") as ofile:\n",
    "            pickle.dump(mass_scaler, ofile)\n",
    "        \n",
    "        for b in bands:\n",
    "            proccessed_data_dict_OS[b][feat] = mass_scaler.transform(preproc_dicts_OS[b][code][feat].reshape(-1,1))\n",
    "            proccessed_data_dict_SS[b][feat] = mass_scaler.transform(preproc_dicts_SS[b][code][feat].reshape(-1,1))\n",
    "            sizes_dict_OS[b] = proccessed_data_dict_OS[b][feat].shape[0]\n",
    "            sizes_dict_SS[b] = proccessed_data_dict_SS[b][feat].shape[0]\n",
    "    \n",
    "    else:   \n",
    "        data_all = np.hstack((preproc_dicts_OS[\"SBL\"][code][feat], preproc_dicts_OS[\"SBH\"][code][feat], preproc_dicts_OS[\"SR\"][code][feat])).reshape(-1, 1)\n",
    "        all_min = np.min(data_all)\n",
    "        all_max = np.max(data_all)\n",
    "        # logit transform the features   \n",
    "    \n",
    "        transformed_feats = logit_transform(data_SB, all_min, all_max)\n",
    "        # subtract off mean, std of the training set\n",
    "        mean_to_sub = np.mean(transformed_feats)\n",
    "        std_to_sub = np.std(transformed_feats)\n",
    "        \n",
    "        preprocessing_info[feat] = {\"mean\":mean_to_sub, \"std\":std_to_sub, \"min\":all_min, \"max\":all_max}\n",
    "        \n",
    "        for b in bands:\n",
    "            proccessed_data_dict_OS[b][feat] = (logit_transform(preproc_dicts_OS[b][code][feat], all_min, all_max) - mean_to_sub)/std_to_sub\n",
    "            proccessed_data_dict_SS[b][feat] = (logit_transform(preproc_dicts_SS[b][code][feat], all_min, all_max) - mean_to_sub)/std_to_sub\n",
    "\n",
    "with open(f\"{processed_data_dir}/preprocessing_info_bootstrap{bootstrap_seed}\", \"wb\") as ofile:\n",
    "            pickle.dump(preprocessing_info, ofile)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d5105e-bb86-4e82-a30d-fed0fd4d5088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(sizes_dict_OS)\n",
    "print(sizes_dict_SS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7080a019-aa16-40b9-801b-5a87663ffe34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist_all_features_dict([proccessed_data_dict_OS[\"SBL\"], proccessed_data_dict_OS[\"SBH\"], proccessed_data_dict_OS[\"SR\"]], \n",
    "                       [\"SBL\", \"SBH\", \"SR\"], feature_set, kwargs_dict_bands, scaled_features=True, plot_bound=5, image_path=None, yscale_log=False, nice_labels=True)\n",
    "\n",
    "\n",
    "hist_all_features_dict([proccessed_data_dict_SS[\"SBL\"], proccessed_data_dict_SS[\"SBH\"], proccessed_data_dict_SS[\"SR\"]], \n",
    "                       [\"SBL\", \"SBH\", \"SR\"], feature_set, kwargs_dict_bands, scaled_features=True, plot_bound=10, image_path=None, yscale_log=False, nice_labels=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dff8207-506b-4d1e-a707-d394ef6f7e37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "trial_test_set = mass_scaler.inverse_transform(np.concatenate((proccessed_data_dict_OS[\"SBL\"][\"dimu_mass\"], proccessed_data_dict_OS[\"SBH\"][\"dimu_mass\"], proccessed_data_dict_OS[\"SR\"][\"dimu_mass\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc77114-e67d-4756-952e-59a0dffe79ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 9))\n",
    "\n",
    "\n",
    "# get the fit function to SB background\n",
    "popt_0, pcov_0, _, _, _ = curve_fit_m_inv(trial_test_set, bkg_fit_type, SR_left, SR_right, plot_bins_left, plot_bins_right, plot_centers_SB, SBL_rescale=None, SBH_rescale=None)\n",
    "plt.plot(plot_centers_all, bkg_fit_function(plot_centers_all, *popt_0), lw = 2, linestyle = \"dashed\")    \n",
    "\n",
    "S, B, q0 = calculate_test_statistic(trial_test_set, bkg_fit_function, bkg_fit_type, plot_bins_SR, plot_centers_SR, SR_left, SR_right, popt_0, pcov_0)\n",
    "label_string = \"sig: \"+str(round(np.sqrt(q0),4))\n",
    "plt.hist(trial_test_set, bins = plot_bins_all, lw = 3, histtype = \"step\",label = label_string)\n",
    "    \n",
    "plt.legend(loc = (1, 0), fontsize = 24)\n",
    "\n",
    "plt.axvline(SR_left, color= \"k\", lw = 3, zorder = -10)\n",
    "plt.axvline(SR_right, color= \"k\", lw = 3, zorder = -10)\n",
    "plt.xlabel(\"$M_{\\mu\\mu}$ [GeV]\", fontsize = 24)\n",
    "plt.ylabel(\"Counts\", fontsize = 24)\n",
    "plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05e28c9-c8d1-449b-a453-b8d46f1f3376",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(f\"{processed_data_dir}/bootstrap{bootstrap_seed}_OS_test_band_data\", \"wb\") as ofile:\n",
    "    pickle.dump(proccessed_data_dict_OS, ofile)\n",
    "with open(f\"{processed_data_dir}/bootstrap{bootstrap_seed}_SS_test_band_data\", \"wb\") as ofile:\n",
    "    pickle.dump(proccessed_data_dict_SS, ofile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6542b296-826b-446e-ad19-31c557d76630",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06cbe07-44f5-4a5d-99df-d67d27b0d3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7800495d-0f11-4907-9b50-518c6f8f754d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5551d7-64a4-424d-a238-47d4989c7db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b1899b-7586-485e-8f3f-953c0116ac19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ce6e7a-b502-4e2f-9df5-e181c9247e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df17ba0a-1f8f-45e9-986e-497ff7cf6bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
