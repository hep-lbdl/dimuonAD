{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddb775fe-c489-49a3-a5be-b0d57a5b3b89",
   "metadata": {},
   "source": [
    "On perlmutter: use kernel pytorch-1.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f83de9b-60cf-4e6d-b9c9-051de67efb6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install nflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2d3ec4-11be-455b-bd30-52614bda6634",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from numba import cuda \n",
    "\n",
    "from helpers.make_flow import *\n",
    "from helpers.train_flow import *\n",
    "from helpers.make_BC import *\n",
    "from helpers.train_BC import *\n",
    "\n",
    "seed = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2975a2b1-68c7-426a-abac-8f741f478a40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# computing\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "\n",
    "# set the number of threads that pytorch will use\n",
    "torch.set_num_threads(2)\n",
    "\n",
    "# set gpu device\n",
    "device = torch.device( \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print( \"Using device: \" + str( device ), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696c9b22-5b46-4a78-98f5-04366163df7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load in the data\n",
    "\n",
    "SB_data = np.load(f\"processed_data/od_SB.npy\")\n",
    "SR_data = np.load(f\"processed_data/od_SR.npy\")\n",
    "\n",
    "print(f\"SB data has shape {SB_data.shape}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0153764c-6258-43d5-8c4f-004e0b76ebf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train val test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SB_data_train, SB_data_val = train_test_split(SB_data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"SB train data has shape {SB_data_train.shape}.\")\n",
    "print(f\"SB val data has shape {SB_data_val.shape}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b20ce9c-9eb9-4a45-8b04-cb8793c7edc1",
   "metadata": {},
   "source": [
    "## Flow creation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404d8e3c-735b-4ad7-94f1-84aa7d40f9c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the flow\n",
    "\n",
    "# This will be the upper subdirectory in saved_models/\n",
    "\n",
    "num_layers = 1\n",
    "num_hidden_features = 128\n",
    "num_blocks = 15\n",
    "flow_training_id = f\"Masked_PRQ_AR_{num_layers}layers_{num_blocks}hidden_{num_blocks}blocks_{seed}seed\"\n",
    "\n",
    "flow_training_dir = os.path.join(\"models\", f\"{flow_training_id}/\")\n",
    "os.makedirs(flow_training_dir, exist_ok=True)\n",
    "\n",
    "hyperparameters_dict = {\"n_epochs\":100,\n",
    "                          \"batch_size\": 128,\n",
    "                          \"lr\": 0.0001,\n",
    "                          \"weight_decay\": 0.0001}\n",
    "\n",
    "\n",
    "test_flow = make_masked_AR_flow(SB_data_train.shape[1]-1, num_layers, num_hidden_features, num_blocks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e796df4-1797-4450-91df-ec0284370f73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "epochs, losses, losses_val, best_epoch = train_flow(test_flow, hyperparameters_dict, device, SB_data_train, SB_data_val, flow_training_dir, seed = seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee5d75b-7538-4a83-9ff1-a1ce20a0f167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(epochs, losses, label = \"loss\")\n",
    "plt.plot(epochs, losses_val, label = \"val loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(best_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fef8637-567e-4d0b-869d-d1bc7c7496e8",
   "metadata": {},
   "source": [
    "## BC training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fcbcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from the flow\n",
    "\n",
    "   \n",
    "# Load in model\n",
    "config_string = \"epochs{0}_lr{1}_wd{2}_bs{3}\".format(hyperparameters_dict[\"n_epochs\"], hyperparameters_dict[\"lr\"], hyperparameters_dict[\"weight_decay\"], hyperparameters_dict[\"batch_size\"])\n",
    "checkpoint_path = os.path.join(flow_training_dir, f\"{config_string}\")\n",
    "    \n",
    "print(f\"Loading in the best flow model model ...\")\n",
    "flow_best = torch.load(f\"{checkpoint_path}_best_model.pt\")\n",
    "flow_best.to(device)\n",
    "\n",
    "# freeze the trained model\n",
    "for param in flow_best.parameters():\n",
    "    param.requires_grad = False\n",
    "flow_best.eval()\n",
    "\n",
    "context_masses = torch.tensor(SR_data[:,-1].reshape(-1,1)).float().to(device)\n",
    "SR_samples = flow_best.sample(1, context=context_masses).detach().cpu().numpy()\n",
    "SR_samples = SR_samples.reshape(SR_samples.shape[0], 8)\n",
    "\n",
    "SR_samples = np.hstack((SR_samples, np.reshape(SR_data[:,-1], (-1, 1))))\n",
    "print(SR_samples.shape)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14f6eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    plt.figure()\n",
    "    plt.hist(SR_data[:,i], bins = np.linspace(-5, 5, 30), density = True, label = \"data\", histtype = \"step\")\n",
    "    plt.hist(SR_samples[:,i], bins = np.linspace(-5, 5, 30), density = True, label = \"samples\", histtype = \"stepfilled\", alpha = 0.5)\n",
    "\n",
    "    #plt.xlabel(labels[i])\n",
    "    plt.legend()\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380a9730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6210cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_dict_BC = {\"n_epochs\":100,\n",
    "                          \"batch_size\": 128,\n",
    "                          \"lr\": 0.0001,\n",
    "                         }\n",
    "\n",
    "\n",
    "discriminate_datasets_kfold(flow_training_dir, SR_samples, SR_data, np.ones((SR_samples.shape[0],1)), np.ones((SR_data.shape[0],1)), \n",
    "                               SR_samples, SR_data, 9, hyperparameters_dict_BC, device, seed = seed)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a794ae-514d-454f-a731-c38c6830c051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864fd8d6-6bc6-449a-9f35-0fb9e71ab568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2580308e-5cd4-44a9-9ce3-0ec6974f3830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9f9ca0-1c54-4cb8-b9d0-957e9823071b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.13.1",
   "language": "python",
   "name": "pytorch-1.13.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
